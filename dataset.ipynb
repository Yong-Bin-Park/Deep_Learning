{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b8b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run mathutil.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02503a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, name, mode):\n",
    "        self.name = name\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}({}, {}+{}+{})'.format(self.name, self.mode, \\\n",
    "                   len(self.tr_xs), len(self.te_xs), len(self.va_xs))\n",
    "\n",
    "    #train_count() 메서드는 @property라는 데코레이터를 갖고 있으며\n",
    "    #이에 따라 실제로는 함수 메서드이면서도 함수가 아닌 속성으로 취급되어 'a.train_count()'형식 대신 인수 구조 없이 'a.train_count'형식으로\n",
    "    #접근할 수 있게 된다. 물론 이런 메서드는 self 외의 매개변수를 가져서는 안된다.\n",
    "    @property\n",
    "    def train_count(self):\n",
    "        return len(self.tr_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc8141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터 공급 메서드 정의\n",
    "#모델 객체에 미니배치 학습 데이터를 공급하는 역할하는 메서드 정의\n",
    "def dataset_get_train_data(self, batch_size, nth):\n",
    "    #미니배치 크기 batch_size와 순번 nth값에 따라 반환 영역을 산정하여\n",
    "    from_idx = nth * batch_size\n",
    "    to_idx = (nth + 1) * batch_size\n",
    "\n",
    "    #미리 준비된 학습 데이터셋 입출력 성분의 일부를 반환한다.\n",
    "    tr_X = self.tr_xs[self.indices[from_idx:to_idx]]\n",
    "    tr_Y = self.tr_ys[self.indices[from_idx:to_idx]]\n",
    "\n",
    "    return tr_X, tr_Y\n",
    "\n",
    "#학습용 데이터를 뒤섞어주는 메서드 정의\n",
    "def dataset_shuffle_train_data(self, size):\n",
    "    #학습용 데이터 부분에 대해서만 새로 뒤섞기를 한다.\n",
    "    self.indices = np.arange(size)\n",
    "    np.random.shuffle(self.indices)\n",
    "\n",
    "Dataset.get_train_data = dataset_get_train_data\n",
    "Dataset.shuffle_train_data = dataset_shuffle_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b2da0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#평가 데이터 공급 메서드 정의\n",
    "def dataset_get_test_data(self):\n",
    "    return self.te_xs, self.te_ys\n",
    "\n",
    "Dataset.get_test_data = dataset_get_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8636bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#검증 데이터 공급 메서드 정의\n",
    "def dataset_get_validate_data(self, count):\n",
    "    self.va_indices = np.arange(len(self.va_xs))\n",
    "    np.random.shuffle(self.va_indices)\n",
    "\n",
    "    va_X = self.va_xs[self.va_indices[0:count]]\n",
    "    va_Y = self.va_ys[self.va_indices[0:count]]\n",
    "\n",
    "    return va_X, va_Y\n",
    "\n",
    "Dataset.get_validate_data = dataset_get_validate_data\n",
    "Dataset.get_visualize_data = dataset_get_validate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e9b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 뒤섞기 메서드 정의\n",
    "#파생 클래스들이 이용할 뒤섞기 메서드 정의\n",
    "def dataset_shuffle_data(self, xs, ys, tr_ratio=0.8, va_ratio=0.05):\n",
    "    #tr_ratio,va_ratio값으로 지정한 비율에 따라 학습과 평가 및 검증용 데이터 수를 계산한다.\n",
    "    data_count = len(xs)\n",
    "\n",
    "    tr_cnt = int(data_count * tr_ratio / 10) * 10\n",
    "    va_cnt = int(data_count * va_ratio)\n",
    "    te_cnt = data_count - (tr_cnt + va_cnt)\n",
    "\n",
    "    #그런 후에 이들 데이터 수에 따라 세 영역의 구간 시작과 끝 위치를 계산한다.\n",
    "    tr_from, tr_to = 0, tr_cnt\n",
    "    va_from, va_to = tr_cnt, tr_cnt + va_cnt\n",
    "    te_from, te_to = tr_cnt + va_cnt, data_count\n",
    "\n",
    "    #이어서 난수 함수를 이용해 데이터 뒤섞기용 인덱스를 만들고\n",
    "    indices = np.arange(data_count)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    #준비된 정보에 따라 데이터를 세 영역으로 분할해 저장한다.\n",
    "    self.tr_xs = xs[indices[tr_from:tr_to]]\n",
    "    self.tr_ys = ys[indices[tr_from:tr_to]]\n",
    "    self.va_xs = xs[indices[va_from:va_to]]\n",
    "    self.va_ys = ys[indices[va_from:va_to]]\n",
    "    self.te_xs = xs[indices[te_from:te_to]]\n",
    "    self.te_ys = ys[indices[te_from:te_to]]\n",
    "\n",
    "    #xs와 ys에서 각각 하나씩 데이터 형태를 조사하여 객체 변수 input_shape와 output_shape에 저장한다.\n",
    "    self.input_shape = xs[0].shape\n",
    "    self.output_shape = ys[0].shape\n",
    "    \n",
    "    #나중에 정의할 파생 클래스에서 뒤섞인 데이터들의 원래 위치를 알 필요가 있을 때를 대비해\n",
    "    #세 데이터 영역에 대한 원본의 위치 정보를 반환한다.\n",
    "    return indices[tr_from:tr_to], indices[va_from:va_to], indices[te_from:te_to]\n",
    "\n",
    "Dataset.shuffle_data = dataset_shuffle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf48d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#후처리 순전파 처리 지원 메서드 정의\n",
    "def dataset_forward_postproc(self, output, y, mode=None):\n",
    "    #mode 매개변숫값이 None이 아니면 이를 대신 이용한다.\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression':\n",
    "        #1.10.9절:단층 퍼셉트론에 대한 순전파 및 역전파 함수 정의\n",
    "        diff = output - y\n",
    "        square = np.square(diff)\n",
    "        loss = np.mean(square)\n",
    "        aux = diff\n",
    "    elif mode == 'binary':\n",
    "        #2.9.4절:후처리 과정에 대한 순전파와 역전파 함수의 재정의\n",
    "        entropy = sigmoid_cross_entropy_with_logits(y, output)\n",
    "        loss = np.mean(entropy)\n",
    "        aux = [y, output]\n",
    "    elif mode == 'select':\n",
    "        #3.8.4절:후처리 과정에 대한 순전파와 역전파 함수의 재정의\n",
    "        entropy = softmax_cross_entropy_with_logits(y, output)\n",
    "        loss = np.mean(entropy)\n",
    "        aux = [output, y, entropy]\n",
    "        \n",
    "    return loss, aux\n",
    "\n",
    "Dataset.forward_postproc = dataset_forward_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e075a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#후처리 역전파 처리 지원 메서드 정의\n",
    "def dataset_backprop_postproc(self, G_loss, aux, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression':\n",
    "        #1.10.9절:단층 퍼셉트론에 대한 순전파 및 역전파 함수 정의\n",
    "        diff = aux\n",
    "        shape = diff.shape\n",
    "\n",
    "        g_loss_square = np.ones(shape) / np.prod(shape)\n",
    "        g_square_diff = 2 * diff\n",
    "        g_diff_output = 1\n",
    "\n",
    "        G_square = g_loss_square * G_loss\n",
    "        G_diff = g_square_diff * G_square\n",
    "        G_output = g_diff_output * G_diff\n",
    "    elif mode == 'binary':\n",
    "        #2.9.4절:후처리 과정에 대한 순전파와 역전파 함수의 재정의\n",
    "        y, output = aux\n",
    "        shape = output.shape\n",
    "\n",
    "        g_loss_entropy = np.ones(shape) / np.prod(shape)\n",
    "        g_entropy_output = sigmoid_cross_entropy_with_logits_derv(y, output)\n",
    "\n",
    "        G_entropy = g_loss_entropy * G_loss\n",
    "        G_output = g_entropy_output * G_entropy\n",
    "    elif mode == 'select':\n",
    "        #3.8.4절:후처리 과정에 대한 순전파와 역전파 함수의 재정의\n",
    "        output, y, entropy = aux\n",
    "\n",
    "        g_loss_entropy = 1.0 / np.prod(entropy.shape)\n",
    "        g_entropy_output = softmax_cross_entropy_with_logits_derv(y, output)\n",
    "\n",
    "        G_entropy = g_loss_entropy * G_loss\n",
    "        G_output = g_entropy_output * G_entropy\n",
    "    \n",
    "    return G_output\n",
    "\n",
    "Dataset.backprop_postproc = dataset_backprop_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74ddecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확도 계산 메서드 정의\n",
    "def dataset_eval_accuracy(self, x, y, output, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression':\n",
    "        mse = np.mean(np.square(output - y))\n",
    "        accuracy = 1 - np.sqrt(mse) / np.mean(y)\n",
    "    elif mode == 'binary':\n",
    "        estimate = np.greater(output, 0)\n",
    "        answer = np.equal(y, 1.0)\n",
    "        correct = np.equal(estimate, answer)\n",
    "        accuracy = np.mean(correct)\n",
    "    elif mode == 'select':\n",
    "        estimate = np.argmax(output, axis=1)\n",
    "        answer = np.argmax(y, axis=1)\n",
    "        correct = np.equal(estimate, answer)\n",
    "        accuracy = np.mean(correct)\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "Dataset.eval_accuracy = dataset_eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70db07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#추정 결과 변환 메서드 정의\n",
    "def dataset_get_estimate(self, output, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression':\n",
    "        #추가 처리 없이 output을 그대로 추정 결과로 삼는다.\n",
    "        estimate = output\n",
    "    elif mode == 'binary':\n",
    "        #로짓값 벡터를 시그모이드 함수를 이용하여 원소 단위의 확률 벡터로 변환\n",
    "        estimate = sigmoid(output)\n",
    "    elif mode == 'select':\n",
    "        #소프트맥스 함수를 이용하여 하나의 확률 분포 벡터로 변환\n",
    "        estimate = softmax(output)\n",
    "        \n",
    "    return estimate\n",
    "\n",
    "Dataset.get_estimate = dataset_get_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b759afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#로그 출력 메서드 정의\n",
    "def dataset_train_prt_result(self, epoch, costs, accs, acc, time1, time2):\n",
    "    print('    Epoch {}: cost={:5.3f}, accuracy={:5.3f}/{:5.3f} ({}/{} secs)'. \\\n",
    "          format(epoch, np.mean(costs), np.mean(accs), acc, time1, time2))\n",
    "\n",
    "def dataset_test_prt_result(self, name, acc, time):\n",
    "    print('Model {} test report: accuracy = {:5.3f}, ({} secs)\\n'. \\\n",
    "          format(name, acc, time))\n",
    "\n",
    "Dataset.train_prt_result = dataset_train_prt_result\n",
    "Dataset.test_prt_result = dataset_test_prt_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
